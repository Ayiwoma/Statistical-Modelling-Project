# Final-Project-Statistical-Modelling-with-Python

This project aims to explore and utilize statistical modeling techniques using Python for comprehensive data analysis. Leveraging the power of Python's
rich ecosystem of libraries such as NumPy, Pandas, Matplotlib, Seaborn, and Sciki-learn, the project seeks to delve into various statistical concepts
and methodoligies to derive actionable insights from data.

## Project/Goals

1. Mastery of Python Fundamentals: Begin by solidifying proficiency in Python programming, encompassing core concepts like variables, loops, conditionals,
   functions, and data structures. This foundational knowledge will serve as a springboard for the subsequent statistical modeling tasks.

2. Understanding Statistical Concepts: Gain a deep understanding of fundamental statistical principles, including probability distributions, hypothesis testing,
   regression analysis, and statistical inference. This comprehension lays the groundwork for effective application of statistical modeling techniques.

3. Exploratory Data Analysis(EDA): Practice conducting EDA on diverse datasets to uncover patterns, trendsm and anomalies. Utilize visualization libraries
   like Matplotlib and Seaborn to create insightful plots and graphs that facilitate data exploration and interpretation.

4. Linear Regression: Master the implementation of linear regression models for modeling relationships between variables. Learn to assess model assumptions,
   perform diagnostics, and interpret regression coefficients to extract meaningful insights from data.

5. Logistic Regression: Extend modeling capabilities to classification problems through logistic regression. Develop proficiency in building binary and
   multinomial logistic regression models, evaluating model performance, and interpreting coefficients to make informed decisions.

6. Real-world Applications: Apply acquired statistical modeling skills to real-world datasets and problems across diverse domains.
   Engage in hands-on projects to address practical challenges and derive actionable insights from data.
   
Conclusion:

Through systematic exploration and application of statistical modeling techniques with Python, this project aims to empower one with the knowledge and 
skills to extract valuable insights from data, make data-driven decisions, and drive positive outcomes across various domains.
By achieving the outlined goals, one will emerge proficient in statistical modeling with Python, equipped to tackle complex data analysis challenges with confidence and efficacy.

## Process
### The provcesRetrieve data from two different API using python

The process involved in this project involved several steps.

1. Define the problem and objectives

   Explore the data retrieved from the city bikes, yelp and foursquare API, join this data using python with focus on        London, Uk by converting this data to csv

2. Filter this data, analyze and interpret this data. This enables conclusions to be drawn of the findings from this data 
   its potential impact.
  
3. Document the results gotten from the retrieved data and process it by using visualization such as histogram etc to        present these findings to stakeholders as well as make recommendations or insights based on analysis retrieved from 
   this data.
   
### (your step 2)

## Results
(fill in what you found about the comparative quality of API coverage in your chosen area and the results of your model.)

The results gotten from this data showed the city bikes produced more details than yelp and foursquare and in the aspect of merging this data, showed that yelp was able to provide more detailed results than foursquare.

## Challenges 
(discuss challenges you faced in the project)
In comparison the caused some challenges as foursquare data did not produce as much details as yelp and city bike, this limited comparison in areas like ratings as I was unable to compare the data from yelp and foursquare using the parameter of ratings because foursquare did not have ratings data availble.

## Future Goals
(what would you do if you had more time?)
Explore another city to compare if foursquare API will provide more detailed data as against the missing values gotten when the city London UK was used, it would have shown if the challenges achieved when trying to retrieve the data would not have happened if I had used another city.
